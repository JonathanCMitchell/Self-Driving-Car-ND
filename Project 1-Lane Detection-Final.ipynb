{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Project 1: Lane Detection </h1>\n",
    "<ul>Tools are my disposal:\n",
    "<li>Color_selection</li>\n",
    "<li>Region of interest selection</li>\n",
    "<li>Grayscaling</li>\n",
    "<li>Gaussian Smoothing</li>\n",
    "<li>Canny edge detection</li>\n",
    "<li>Hough Transform line detection</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  ['whiteCarLaneSwitch.jpg', 'solidWhiteCurve.jpg', 'solidYellowCurve.jpg', 'solidYellowLeft.jpg', 'solidYellowCurve2.jpg', 'solidWhiteRight.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = os.listdir(\"test_images/\")\n",
    "print('images: ', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "def readImage(image):\n",
    "    image = mpimg.imread('test_images/' + image)\n",
    "    gray = grayscale(image)\n",
    "    blur_gray = apply_gaussian_blur(gray)\n",
    "    edges = apply_canny(blur_gray)\n",
    "    masked_image = apply_mask(edges, image, gray)\n",
    "    hough_image, lines = apply_hough(masked_image)\n",
    "    lines_edges_weighted = apply_lines_edges_weighted(image, edges, hough_image)\n",
    "    plot_mask(edges, image, masked_image)\n",
    "    plot_hough(hough_image, lines)\n",
    "    plot_mask_and_hough(masked_image, hough_image)\n",
    "    plot_weighted_image(lines_edges_weighted)\n",
    "    return lines_edges_weighted\n",
    "\n",
    "# Read in one image and output the result\n",
    "def readAllImages(images):\n",
    "    for img in images:\n",
    "        result = readImage(img)\n",
    "        mpimg.imsave('results_rendered/' + '-ChangedParameters--'+img, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we convert the image to grayscale we simply take off the RGB values and provide 1 value instead.\n",
    "<li>Shape of image: (960, 540, 3)</li>\n",
    "<li>Shape of gray: (960, 540)</li>\n",
    "No 3rd dimension on Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then provide a Gaussian Blur to reduce noise/detail from the image. This process is the same as convolving the image with a Gaussian function. It smoothes out the edges.\n",
    "<li>Shape of gray: (540, 960)</li>\n",
    "<li>Shape of blur_gray: (540, 960)</li>\n",
    "<li>Gaussian Blur also takes in a kernel_size. A larger kernel_size implies averaging over a larger area. They must be odd, typically 3 or 5 work well.</li>\n",
    "<li> A ratio of 1:2 or 1:3 Low:High threshold is recommended.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian Blur\n",
    "def apply_gaussian_blur(gray, kernel_size = 5):\n",
    "    return gaussian_blur(gray, kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define parameters for the Canny function, which will take in an image, a low_threshold, and a high_threshold\n",
    "<li>pixel values below low_threshold are discarded</li>\n",
    "<li>pixel values above high_threshold are considered to be edges</li>\n",
    "<li>pixel values between low and high thresholds are kept if they are touching a pixel above high threshold (edges)</li>\n",
    "\n",
    "<h3>Canny Input</h3><h5>blur_gray (shape: (540,960)</h5>\n",
    "<h3>Canny Output</h3><h5>edges (shape:(540, 960) </h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Parameters for Canny\n",
    "def apply_canny(blur_gray, low_threshold = 75, high_threshold = 175):\n",
    "    # Apply Canny, changes pixel values to be either 0 (black) or 255 (white)\n",
    "    return canny(blur_gray, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Mask / Region of interest</h3>\n",
    "<p>Next we wish to apply an image mask to only consider lane lines in a surrounding polygon</p>\n",
    "<p>Here we will use the <strong>cv2.fillPoly(mask, vertices, ignore_mask_color) function </strong></p>\n",
    "<li>Input edges shape: (540, 960) Output: masked Image shape: (540, 960) </li>\n",
    "<li>Function does not change input 'edges'</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_mask(edges, image, gray):\n",
    "    #make general shape of mask\n",
    "    mask = np.zeros_like(edges)\n",
    "    # create ignore mask color = 255\n",
    "    ignore_mask_color = 255 \n",
    "\n",
    "    # create vertices for region\n",
    "    imshape = image.shape\n",
    "\n",
    "    \n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    x_middle = xsize/2\n",
    "    x_offset = 55 # from 55\n",
    "    \n",
    "    y_middle = ysize/2\n",
    "    y_offset = 45 # from 45\n",
    "    vertices = np.array([[(0, ysize),\n",
    "                         (x_middle - x_offset, y_middle + y_offset),\n",
    "                         (x_middle + x_offset, y_middle + y_offset),\n",
    "                         (xsize, ysize)]], dtype=np.int32)\n",
    "    \n",
    "\n",
    "    # Polyfill the mask and do a bitwise_and to keep only edges in the region\n",
    "    (masked_image, mask) = region_of_interest(edges, vertices)\n",
    "    return masked_image\n",
    "\n",
    "def plot_mask(edges, image, masked_image):\n",
    "    # PLOT\n",
    "    fig = plt.figure()\n",
    "\n",
    "    a = fig.add_subplot(3,1,1)\n",
    "    edgeplot = plt.imshow(edges, cmap=\"gray\")\n",
    "    a.set_title('Edges')\n",
    "\n",
    "    a = fig.add_subplot(3,1,2)\n",
    "    a.set_title('Image')\n",
    "    edgeplot = plt.imshow(image)\n",
    "\n",
    "    a = fig.add_subplot(3,1,3)\n",
    "    a.set_title('Masked Image')\n",
    "    edgeplot = plt.imshow(masked_image, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hough Lines</h3>\n",
    "<li>Now that we have masked image Shape: (540, 960). We can use <strong>lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)</strong> to get a row vector of our lines</li>\n",
    "<li>Copy the image to draw on <strong>line_image</strong> (row vecto with (x1,y1,x2,y2) as elements).</li>\n",
    "<li>Iterate through the rows of lines, then grab each element (x1, y1, x2, and y2) and use <strong>cv2.line(<strong>line_image</strong>, pt1, pt2, color, thickness)</strong> to draw lines</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_hough(masked_image):\n",
    "    theta = np.pi/180     \n",
    "    rho = 1.89\n",
    "    threshold = 75\n",
    "    min_line_len = 25\n",
    "    max_line_gap = 125\n",
    "\n",
    "    # Create a line image with hough lines on it\n",
    "    hough_image, lines = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "#     print('lines: ', lines.shape)\n",
    "    # line_zero[:,1,0] = lines[:,1,0]\n",
    "\n",
    "    return hough_image, lines\n",
    "    # We gave line_image color when we copied the shape of mask_image and then added a 3rd dimension for our color space.\n",
    "    # Then in draw_lines we input color = [255, 0, 0] so that will be red in this case. \n",
    "    # I changed the input color in draw_lines to [0, 255, 0] so we get green \n",
    "\n",
    "def plot_hough(hough_image, lines):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    b = fig.add_subplot(2,1,1)\n",
    "    edgeplot = plt.imshow(lines)\n",
    "    b.set_title('Lines')\n",
    "\n",
    "    b = fig.add_subplot(2,2,2)\n",
    "    b.set_title('Hough Image')\n",
    "    edgeplot = plt.imshow(hough_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the line image. And we have the masked image/masked edges\n",
    "The next step is to draw the line_image ontop of the masked_image\n",
    "<li>Shape of masked_image: (540, 960)</li>\n",
    "<li>Shape of line_image: (540,960, 3)...This one has color</li> \n",
    "<h5>Plot of line image vs mask image</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_mask_and_hough(masked_image, hough_image):\n",
    "    fig = plt.figure()\n",
    "    c = fig.add_subplot(1,2,1)\n",
    "    edgeplot = plt.imshow(masked_image, cmap=\"gray\")\n",
    "    c.set_title('masked_image')\n",
    "\n",
    "    c = fig.add_subplot(1,2,2)\n",
    "    c.set_title('Hough_image')\n",
    "    edgeplot = plt.imshow(hough_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Img is the output of hough lines ==> lines_image\n",
    "# initial_image is the color_edges, which is the initial edges image with a 3rd dimension for color\n",
    "# Edges shape: (540, 960)\n",
    "def apply_lines_edges_weighted(image, edges, hough_image):\n",
    "    lines_edges_weighted = weighted_img(hough_image, image)\n",
    "    return lines_edges_weighted\n",
    "\n",
    "def plot_lines_edges_weighted_hough_and_original():\n",
    "    # PLOT\n",
    "    fig = plt.figure()\n",
    "    d = fig.add_subplot(3,1,1)\n",
    "    line_edgeplot = plt.imshow(hough_image)\n",
    "    d.set_title('hough_image')\n",
    "\n",
    "    d = fig.add_subplot(3,1,2)\n",
    "    line_edgeplot = plt.imshow(color_edges)\n",
    "    d.set_title('color_edges')\n",
    "\n",
    "    d = fig.add_subplot(3,1,3)\n",
    "    line_edgeplot = plt.imshow(lines_edges_weighted)\n",
    "    d.set_title('lines_edges_weighted')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_weighted_image(lines_edges_weighted):\n",
    "    plt.imshow(lines_edges_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converts image to grayscale\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Applies canny transform\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "# Applies gaussian noise kernel, typically use kernel size of 3 or 5. (odd numbers only)\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:  #if it is 3 or 4 channels; RGB or RGBT\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count  #so you can fill multiple colors\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    # Because we just filled the mask matrix with vertices in the *fillPoly* function.\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return (masked_image, mask)\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[0, 255, 0], thickness=11):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    x1_values = lines[:, :, 0]\n",
    "    y1_values = lines[:, :, 1]\n",
    "    x2_values = lines[:, :, 2]\n",
    "    y2_values = lines[:, :, 3]\n",
    "\n",
    "\n",
    "    global prev_left_x_min\n",
    "    global prev_left_x_max\n",
    "    global prev_right_x_min\n",
    "    global prev_right_x_max\n",
    "\n",
    "    y_max = max(np.amax(y1_values), np.amax(y2_values))\n",
    "    y_min = max(np.amin(y1_values), np.amin(y2_values))\n",
    "    left_slopes = []\n",
    "    right_slopes = []\n",
    "\n",
    "    right_lane = []\n",
    "    left_lane = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "\n",
    "#             if slope < 0:  #left lane has negative slope\n",
    "            if (-0.9 < slope < -0.6):\n",
    "                left_slopes.append(slope)\n",
    "                left_lane.append(line)\n",
    "            elif 0.45 < slope < 0.7: # right lane positive slope\n",
    "                right_slopes.append(slope)\n",
    "                right_lane.append(line)\n",
    "\n",
    "    left_slopes_arr = np.array(left_slopes)\n",
    "    right_slopes_arr = np.array(right_slopes)\n",
    "\n",
    "    left_lines_arr = np.array(left_lane)\n",
    "    right_lines_arr = np.array(right_lane)\n",
    "\n",
    "    # Find average slopes\n",
    "    left_lane_slope_average = np.mean(left_slopes_arr)  # type numpy.float64\n",
    "    right_lane_slope_average = np.mean(right_slopes_arr)\n",
    "\n",
    "    y_max = int(y_max)\n",
    "    y_min = int(y_min)\n",
    "\n",
    "    if len(left_lines_arr) > 0:\n",
    "        # Compute Left lane intercept:\n",
    "        y_intercept_left_lane_average = np.mean(left_lines_arr[:, :, 1] - (left_lines_arr[:, :, 0] * left_lane_slope_average))\n",
    "\n",
    "        # Compute Left lane Xmax and Xmin:\n",
    "        x_max_left = int((y_max - y_intercept_left_lane_average) / left_lane_slope_average)\n",
    "        x_min_left = int((y_min - y_intercept_left_lane_average) / left_lane_slope_average)\n",
    "            \n",
    "\n",
    "        cv2.line(img, (x_max_left, y_max), (x_min_left, y_min), color, thickness)\n",
    "        # Save last coordinates to keep line going\n",
    "        \n",
    "        prev_left_x_max = x_max_left\n",
    "        prev_left_x_min = x_min_left\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if prev_left_x_max is not None:\n",
    "            print('prev_left_x_max is not None')\n",
    "            cv2.line(img, (prev_left_x_max, y_max),(prev_left_x_min, y_min), color, thickness)\n",
    "        else:\n",
    "            print('nothing')\n",
    "            \n",
    "    if len(right_lines_arr) > 0:\n",
    "        # Compute Right Lane Intercept:\n",
    "        y_intercept_right_lane_average = np.mean(right_lines_arr[:, :, 1] - (right_lines_arr[:, :, 0] * right_lane_slope_average))\n",
    "\n",
    "        # Compute Right lane Xmax and Xmin:\n",
    "        x_max_right = int((y_max - y_intercept_right_lane_average) / right_lane_slope_average)\n",
    "        x_min_right = int((y_min - y_intercept_right_lane_average) / right_lane_slope_average)\n",
    "\n",
    "        cv2.line(img, (x_max_right, y_max), (x_min_right, y_min), color, thickness)\n",
    "        prev_right_x_max = x_max_right\n",
    "        prev_right_x_min = x_min_right\n",
    "    else:\n",
    "        if prev_right_x_max is not None:\n",
    "            print('prev_right_x_max is not NONE')\n",
    "#         print(\"right_lines_arr is empty. Not drawing anything as there are no lines to choose from.\")\n",
    "            cv2.line(img, (prev_right_x_max, y_max), (prev_right_x_min, y_min), color, thickness)\n",
    "        else:\n",
    "            \n",
    "            print('nothing right side empty')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        img shape will be 2D output from canny transform\n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    hough_lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
    "                                  maxLineGap=max_line_gap)\n",
    "\n",
    "    # Create a line_img which we will ultimately draw on in our draw lines function\n",
    "    # line_img will become zeros (540, 960, 3). \n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)  #*before img.shape unpacks the tuple\n",
    "\n",
    "    draw_lines(line_img, hough_lines)\n",
    "    return (line_img, hough_lines)\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Video Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save previous coordinates as global variables in case I don't detect any lines on the current frame\n",
    "prev_left_x_min = None\n",
    "prev_left_x_max = None\n",
    "prev_right_x_min = None\n",
    "prev_right_x_max = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    blur_gray = apply_gaussian_blur(gray)\n",
    "    edges = apply_canny(blur_gray)\n",
    "    masked_image = apply_mask(edges, image, gray)\n",
    "    hough_image, lines = apply_hough(masked_image)\n",
    "    lines_edges_weighted = apply_lines_edges_weighted(image, edges, hough_image)\n",
    "    return lines_edges_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video solidWhiteRightx2.mp4\n",
      "[MoviePy] Writing video solidWhiteRightx2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 146/222 [00:02<00:01, 53.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:03<00:00, 60.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: solidWhiteRightx2.mp4 \n",
      "\n",
      "CPU times: user 8.66 s, sys: 68 ms, total: 8.73 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "# Test on solidWhite\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'solidWhiteRightx2.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"solidWhiteRightx2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video solidYellowLeftTestx2.mp4\n",
      "[MoviePy] Writing video solidYellowLeftTestx2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:12<00:00, 55.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: solidYellowLeftTestx2.mp4 \n",
      "\n",
      "CPU times: user 27.4 s, sys: 264 ms, total: 27.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "# Test on solid yellow left\n",
    "yellow_output = 'solidYellowLeftTestx2.mp4'\n",
    "clip2 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"solidYellowLeftTestx2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challengeTestx2.mp4\n",
      "[MoviePy] Writing video challengeTestx2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 36/251 [00:00<00:03, 54.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 58/251 [00:01<00:05, 38.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 104/251 [00:02<00:04, 33.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 112/251 [00:03<00:04, 31.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 116/251 [00:03<00:04, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 124/251 [00:03<00:04, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 127/251 [00:03<00:05, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 133/251 [00:03<00:04, 24.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 139/251 [00:04<00:04, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 142/251 [00:04<00:04, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 148/251 [00:04<00:04, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n",
      "prev_left_x_max is not None\n",
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/251 [00:05<00:03, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_right_x_max is not NONE\n",
      "prev_right_x_max is not NONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 168/251 [00:05<00:03, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_left_x_max is not None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:08<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challengeTestx2.mp4 \n",
      "\n",
      "CPU times: user 13.2 s, sys: 156 ms, total: 13.3 s\n",
      "Wall time: 9.01 s\n"
     ]
    }
   ],
   "source": [
    "# Challenge output\n",
    "challenge_output = 'challengeTestx2.mp4'\n",
    "clip3 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Challenge output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challengeTestx2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Reflection:</h1>\n",
    "A lot of time was spent trying to get my environment to work with moviepy. A greater amount of time was spent understanding what each parameter does and how to effectively draw the lines. I realized later on that some of the functions I had were entirely useless so I have been trying to clean up the code to make it tight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If I had more time I would try to find a way to use curves and sinusoids instead of lines. Possibly doing a least squares fit or something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most difficult part for me in this project was to get the video to render, and to figure out how to work with python and make a global variable for when I do not detect a line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am trying to find a way to analyze the curves in the challenge video, and to trim off the top lines so they don't cross because the video has the lines oriented in different dimensions. I have a lot of plotting functions that were extremely useful when testing on a single image. These allowed me to make sure my mask and hough transform's were accurately grabbing the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
